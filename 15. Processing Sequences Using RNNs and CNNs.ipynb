{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15: Processing Sequences Using RNNs and CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bab ini memperkenalkan **Recurrent Neural Networks (RNNs)**, sebuah kelas jaringan saraf yang dirancang untuk bekerja pada data sekuensial atau data deret waktu (*time series*). Tidak seperti jaringan *feedforward*, RNN memiliki koneksi yang menunjuk ke belakang, memungkinkannya untuk mempertahankan semacam \"memori\" dari input sebelumnya.\n",
    "\n",
    "Aplikasi RNN sangat luas, mulai dari memprediksi harga saham, menganalisis data sensor, hingga pemrosesan bahasa alami (NLP) seperti terjemahan mesin atau analisis sentimen.\n",
    "\n",
    "Kita akan membahas:\n",
    "* Konsep dasar neuron dan lapisan rekuren.\n",
    "* Cara melatih RNN menggunakan *Backpropagation Through Time (BPTT)*.\n",
    "* Kesulitan utama dalam melatih RNN: gradien yang tidak stabil dan memori jangka pendek yang terbatas.\n",
    "* Arsitektur sel yang lebih canggih seperti **LSTM (Long Short-Term Memory)** dan **GRU (Gated Recurrent Unit)** untuk mengatasi masalah memori.\n",
    "* Penggunaan **Convolutional Neural Networks (CNNs)** untuk memproses sekuens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neurons and Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron rekuren (atau sel) tidak hanya menerima input pada waktu `t`, tetapi juga menerima outputnya sendiri dari langkah waktu sebelumnya (`t-1`). Keadaan internal ini, yang disebut *hidden state*, memungkinkan jaringan untuk mengingat informasi dari masa lalu.\n",
    "\n",
    "Sebuah lapisan RNN terdiri dari beberapa sel rekuren yang bekerja secara paralel, masing-masing mempertahankan *hidden state*-nya sendiri. Lapisan ini dapat memproses sekuens dengan panjang berapa pun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting a Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salah satu tugas paling umum untuk RNN adalah *forecasting* (peramalan). Kita akan mencoba memprediksi nilai berikutnya dalam sebuah *time series* sintetis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fungsi untuk membuat dataset time series\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "# Membuat data\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN\n",
    "RNN paling sederhana dapat dibuat menggunakan `SimpleRNN` layer di Keras. Kita akan membangun model untuk memprediksi nilai berikutnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membangun model RNN sederhana\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.005)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Long Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN sederhana kesulitan belajar dari sekuens yang panjang karena dua alasan utama:\n",
    "1. **Unstable Gradients:** Seperti DNN biasa, gradien dapat menghilang atau meledak.\n",
    "2. **Limited Short-Term Memory:** Karena informasi melewati transformasi di setiap langkah, informasi dari langkah-langkah awal dapat hilang.\n",
    "\n",
    "### LSTM and GRU Cells\n",
    "Untuk mengatasi masalah memori, sel yang lebih kompleks seperti **LSTM (Long Short-Term Memory)** dan **GRU (Gated Recurrent Unit)** diperkenalkan. Sel-sel ini memiliki mekanisme *gate* (gerbang) yang memungkinkan jaringan untuk belajar apa yang harus diingat, apa yang harus dilupakan, dan apa yang harus dikeluarkan sebagai output. Ini memungkinkan mereka untuk menangkap dependensi jangka panjang dalam data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membangun model dengan GRU layer\n",
    "model_gru = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_gru.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history_gru = model_gru.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CNNs for Sequences - WaveNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arsitektur **WaveNet**, yang awalnya dikembangkan untuk audio, menunjukkan bahwa CNN juga bisa sangat efektif untuk data sekuensial. Ia menggunakan lapisan 1D *convolutional* dengan *dilation rate* yang meningkat secara eksponensial. Ini memungkinkan jaringan untuk memiliki *receptive field* yang sangat besar, memungkinkannya belajar pola jangka panjang dengan cara yang sangat efisien secara komputasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi Prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melatih model, kita dapat memvisualisasikan prediksinya pada data baru untuk melihat seberapa baik kinerjanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat prediksi pada satu time series dari test set\n",
    "series_test = X_test[0:1, :, :]\n",
    "y_pred = model_gru.predict(series_test)\n",
    "\n",
    "# Fungsi untuk plot\n",
    "def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\"):\n",
    "    plt.plot(series, \"b-\")\n",
    "    if y is not None:\n",
    "        plt.plot(n_steps, y, \"bo\", label=\"Target\")\n",
    "    if y_pred is not None:\n",
    "        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")\n",
    "    plt.grid(True)\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label, fontsize=16)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label, fontsize=16, rotation=0)\n",
    "    plt.hlines(0, 0, 100, linewidth=1)\n",
    "    plt.axis([0, n_steps + 1, -1, 1])\n",
    "    if y is not None or y_pred is not None:\n",
    "        plt.legend(fontsize=14)\n",
    "\n",
    "plot_series(X_test[0, :, 0], y_test[0, 0], y_pred[0, 0])\n",
    "plt.title(\"Prediksi Time Series dengan GRU\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
