{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bab ini membahas masalah yang dikenal sebagai **Curse of Dimensionality** (Kutukan Dimensi), di mana banyak algoritma Machine Learning berkinerja buruk pada dataset dengan jumlah fitur yang sangat tinggi (dimensi tinggi).\n",
    "\n",
    "Kita akan mengeksplorasi teknik-teknik untuk mengurangi jumlah fitur (dimensi) ini, yang dapat mempercepat pelatihan secara signifikan dan terkadang bahkan meningkatkan kinerja model. Mengurangi dimensi juga sangat berguna untuk visualisasi data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masalah utama dalam ruang berdimensi tinggi adalah data menjadi sangat tersebar (*sparse*). Sebagian besar *instance* pelatihan kemungkinan besar akan berjauhan satu sama lain, membuat prediksi menjadi kurang andal karena didasarkan pada ekstrapolasi yang jauh lebih besar. Ini meningkatkan risiko *overfitting*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendekatan Utama untuk Pengurangan Dimensi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada dua pendekatan utama untuk mengurangi dimensi:\n",
    "\n",
    "1.  **Projection (Proyeksi):** Sebagian besar data di dunia nyata tidak tersebar secara seragam di semua dimensi. Seringkali, data berada di dekat *subspace* berdimensi jauh lebih rendah. Proyeksi bekerja dengan memproyeksikan setiap *instance* data ke *subspace* ini. Teknik yang paling populer untuk ini adalah **Principal Component Analysis (PCA)**.\n",
    "\n",
    "2.  **Manifold Learning:** Pendekatan ini mengasumsikan bahwa sebagian besar dataset berdimensi tinggi di dunia nyata berada di dekat *manifold* berdimensi jauh lebih rendah. *Manifold* adalah bentuk yang dapat ditekuk dan diputar dalam ruang berdimensi lebih tinggi (contoh: Swiss roll). Manifold Learning mencoba untuk \"membuka gulungan\" *manifold* ini. Contoh tekniknya adalah **Locally Linear Embedding (LLE)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA adalah algoritma pengurangan dimensi yang paling populer. Ia bekerja dengan mengidentifikasi *hyperplane* yang paling dekat dengan data, lalu memproyeksikan data ke *hyperplane* tersebut.\n",
    "\n",
    "PCA memilih sumbu (disebut *principal component*) yang mempertahankan jumlah varians maksimum dalam data. Sumbu kedua dipilih ortogonal terhadap yang pertama dan mempertahankan sisa varians terbesar, dan seterusnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Membuat dataset 3D\n",
    "np.random.seed(4)\n",
    "m = 60\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X = np.empty((m, 3))\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)\n",
    "\n",
    "# Menggunakan PCA untuk mengurangi dimensi menjadi 2\n",
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(X)\n",
    "\n",
    "print(\"Principal components:\")\n",
    "print(pca.components_)\n",
    "\n",
    "print(\"Explained variance ratio:\")\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel PCA (kPCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti yang kita lihat di bab SVM, *kernel trick* adalah teknik matematis yang memungkinkan kita memetakan *instance* ke ruang berdimensi sangat tinggi secara implisit. Trik yang sama dapat diterapkan pada PCA, yang memungkinkan proyeksi non-linear untuk pengurangan dimensi.\n",
    "\n",
    "Ini disebut **Kernel PCA (kPCA)**. Ini sangat baik dalam mempertahankan klaster *instance* setelah proyeksi atau bahkan membuka dataset yang terletak di dekat *manifold* yang terpilin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Menggunakan kPCA dengan kernel RBF\n",
    "rbf_pca = KernelPCA(n_components=2, kernel=\"rbf\", gamma=0.04)\n",
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLE (Locally Linear Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLE** adalah teknik *Manifold Learning* yang tidak bergantung pada proyeksi. LLE bekerja dengan terlebih dahulu mengukur bagaimana setiap *instance* pelatihan berhubungan secara linear dengan tetangga terdekatnya. Kemudian, ia mencari representasi berdimensi rendah dari set pelatihan di mana hubungan lokal ini paling terjaga.\n",
    "\n",
    "Pendekatan ini membuatnya sangat baik dalam membuka *manifold* yang terpilin, terutama jika tidak ada terlalu banyak *noise*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)\n",
    "X_reduced_lle = lle.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
