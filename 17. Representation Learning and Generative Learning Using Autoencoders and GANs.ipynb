{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bab ini memperkenalkan dua arsitektur jaringan saraf yang kuat dan dapat belajar tanpa data berlabel (*unsupervised learning*): **Autoencoders** dan **Generative Adversarial Networks (GANs)**.\n",
    "\n",
    "Keduanya mampu mempelajari representasi data yang padat (disebut *latent representations* atau *codings*), dan keduanya dapat digunakan sebagai model generatif untuk menghasilkan data baru yang mirip dengan data pelatihan.\n",
    "\n",
    "* **Autoencoders** belajar untuk merekonstruksi inputnya kembali. Dengan memberikan batasan tertentu pada jaringan (misalnya, lapisan tengah yang lebih kecil), kita memaksanya untuk belajar representasi data yang efisien.\n",
    "* **GANs** terdiri dari dua jaringan yang bersaing: *generator* yang mencoba membuat data palsu yang realistis, dan *discriminator* yang mencoba membedakan data asli dari data palsu. Kompetisi ini mendorong kedua jaringan untuk menjadi lebih baik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoencoder** adalah jaringan saraf yang terdiri dari dua bagian:\n",
    "1. **Encoder:** Mengubah input menjadi representasi laten (coding).\n",
    "2. **Decoder:** Mengubah representasi laten kembali menjadi output yang semirip mungkin dengan input asli.\n",
    "\n",
    "Dengan memaksa representasi laten memiliki dimensi yang lebih kecil dari input (*undercomplete autoencoder*), kita memaksa jaringan untuk mempelajari fitur-fitur data yang paling penting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder dapat memiliki beberapa *hidden layer*, yang disebut **stacked autoencoders**. Ini membantunya mempelajari *coding* yang lebih kompleks. Arsitekturnya biasanya simetris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Memuat dataset Fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train_full[5000:].astype(np.float32) / 255\n",
    "X_valid = X_train_full[:5000].astype(np.float32) / 255\n",
    "\n",
    "# Membangun Stacked Autoencoder\n",
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "])\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "\n",
    "stacked_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.5))\n",
    "history = stacked_ae.fit(X_train, X_train, epochs=20, validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi Rekonstruksi\n",
    "Salah satu cara untuk mengevaluasi autoencoder adalah dengan membandingkan input asli dengan hasil rekonstruksinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_reconstructions(model, n_images=5):\n",
    "    reconstructions = model.predict(X_valid[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(X_valid[image_index])\n",
    "        plt.title(\"Original\")\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])\n",
    "        plt.title(\"Reconstructed\")\n",
    "    plt.show()\n",
    "\n",
    "show_reconstructions(stacked_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoders (VAEs)\n",
    "VAEs adalah autoencoder *probabilistic* dan *generative*. Alih-alih menghasilkan *coding* yang pasti, *encoder* menghasilkan *mean* (μ) dan *standard deviation* (σ). *Coding* yang sebenarnya kemudian di-sampel secara acak dari distribusi Gaussian dengan parameter μ dan σ. Ini memungkinkan VAE untuk menghasilkan *instance* baru yang realistis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs menggunakan pendekatan yang berbeda secara fundamental. Mereka terdiri dari dua jaringan yang bersaing:\n",
    "\n",
    "* **Generator:** Mencoba menghasilkan data palsu yang terlihat nyata.\n",
    "* **Discriminator:** Mencoba membedakan antara data nyata dari *training set* dan data palsu dari *generator*.\n",
    "\n",
    "Selama pelatihan, kedua jaringan ini saling mendorong untuk menjadi lebih baik dalam permainan \"kucing dan tikus\" ini. Tujuan akhirnya adalah agar *generator* menjadi sangat baik dalam menghasilkan data sehingga *discriminator* tidak bisa lagi membedakannya dari data asli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Convolutional GANs (DCGANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCGANs adalah varian GAN yang menggunakan *convolutional layer* untuk menghasilkan gambar, yang terbukti sangat efektif. Ada beberapa panduan arsitektur kunci untuk membuat pelatihan DCGAN lebih stabil, seperti menggunakan *transposed convolution* di *generator* dan *strided convolution* di *discriminator*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh konseptual membangun DCGAN sederhana\n",
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
    "    keras.layers.Reshape([7, 7, 128]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\", activation=\"tanh\"),\n",
    "])\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\", activation=keras.layers.LeakyReLU(0.2), input_shape=[28, 28, 1]),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\", activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi Gambar yang Dihasilkan GAN\n",
    "Setelah melatih GAN, kita dapat menggunakannya untuk menghasilkan gambar-gambar baru yang belum pernah ada sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghasilkan dan memplot gambar\n",
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols * 1.5, n_rows * 1.5))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "# Menghasilkan beberapa gambar (setelah model dilatih)\n",
    "noise = tf.random.normal(shape=[10, codings_size])\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "plot_multiple_images(generated_images, n_cols=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
