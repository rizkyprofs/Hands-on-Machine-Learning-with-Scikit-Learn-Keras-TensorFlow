{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Bab 3: Klasifikasi"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Setelah mempelajari alur kerja proyek ML di Bab 2, bab ini menyelam lebih dalam ke salah satu tugas *supervised learning* yang paling umum: **klasifikasi**. Kita akan menggunakan dataset MNIST, yang sering disebut sebagai \"hello world\"-nya Machine Learning, sebagai contoh utama. Bab ini mencakup cara melatih *classifier*, mengukur kinerjanya dengan berbagai metrik, dan menangani berbagai jenis tugas klasifikasi."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Dataset MNIST"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "MNIST adalah dataset berisi 70.000 gambar kecil angka tulisan tangan (0-9) yang dikumpulkan dari siswa SMA dan pegawai Biro Sensus AS. Setiap gambar berukuran 28x28 piksel dan memiliki label angka yang diwakilinya."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from sklearn.datasets import fetch_openml\n",
       "\n",
       "# Memuat dataset MNIST\n",
       "mnist = fetch_openml('mnist_784', version=1)\n",
       "X, y = mnist[\"data\"], mnist[\"target\"]"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Dataset ini sudah dibagi menjadi *training set* (60.000 gambar pertama) dan *test set* (10.000 gambar terakhir). Sangat penting untuk selalu memisahkan *test set* dan tidak menyentuhnya sampai kita siap mengevaluasi model final."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "\n",
       "# Mengubah label dari string ke integer\n",
       "y = y.astype(np.uint8)\n",
       "\n",
       "# Memisahkan training dan test set\n",
       "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Melatih Binary Classifier"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Sebagai langkah awal, kita akan menyederhanakan masalah: mencoba mengidentifikasi satu digit saja, misalnya angka 5. Ini adalah contoh *binary classifier*, yang mampu membedakan antara dua kelas: \"angka 5\" dan \"bukan angka 5\"."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Membuat target untuk binary classification\n",
       "y_train_5 = (y_train == 5)\n",
       "y_test_5 = (y_test == 5)\n",
       "\n",
       "# Memilih dan melatih model\n",
       "from sklearn.linear_model import SGDClassifier\n",
       "\n",
       "sgd_clf = SGDClassifier(random_state=42)\n",
       "sgd_clf.fit(X_train, y_train_5)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Metrik Kinerja"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Mengevaluasi sebuah *classifier* seringkali lebih rumit daripada mengevaluasi *regressor*. Ada beberapa metrik yang perlu kita pahami.\n",
       "\n",
       "### Akurasi Menggunakan Cross-Validation\n",
       "Akurasi adalah rasio prediksi yang benar. Meskipun terdengar intuitif, akurasi bisa menyesatkan, terutama pada dataset yang tidak seimbang (*skewed dataset*).\n",
       "\n",
       "### Confusion Matrix\n",
       "Cara yang jauh lebih baik untuk mengevaluasi kinerja *classifier* adalah dengan melihat *confusion matrix*. Matriks ini menunjukkan berapa kali instance dari kelas A diklasifikasikan sebagai kelas B. Dari sini, kita bisa menghitung metrik yang lebih informatif.\n",
       "\n",
       "Istilah dalam Confusion Matrix:\n",
       "- **True Negatives (TN):** Instance negatif yang diklasifikasikan dengan benar.\n",
       "- **False Positives (FP):** Instance negatif yang salah diklasifikasikan sebagai positif.\n",
       "- **False Negatives (FN):** Instance positif yang salah diklasifikasikan sebagai negatif.\n",
       "- **True Positives (TP):** Instance positif yang diklasifikasikan dengan benar."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from sklearn.model_selection import cross_val_predict\n",
       "from sklearn.metrics import confusion_matrix\n",
       "\n",
       "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
       "\n",
       "print(confusion_matrix(y_train_5, y_train_pred))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Precision dan Recall\n",
       "\n",
       "- **Precision (Presisi):** Akurasi dari prediksi positif. \n",
       "  $$ Precision = \\frac{TP}{TP + FP} $$ \n",
       "  Ini menjawab pertanyaan: \"Dari semua instance yang diprediksi positif, berapa persen yang benar-benar positif?\"\n",
       "\n",
       "- **Recall (Sensitivitas atau True Positive Rate):** Rasio instance positif yang berhasil dideteksi oleh *classifier*.\n",
       "  $$ Recall = \\frac{TP}{TP + FN} $$ \n",
       "  Ini menjawab pertanyaan: \"Dari semua instance yang sebenarnya positif, berapa persen yang berhasil dideteksi?\"\n",
       "\n",
       "Seringkali, ada *trade-off* antara *precision* dan *recall*: meningkatkan yang satu cenderung menurunkan yang lain. Pilihan mana yang lebih penting tergantung pada masalah. Contohnya, untuk mendeteksi video yang aman untuk anak-anak, kita ingin *precision* yang sangat tinggi (lebih baik menolak beberapa video bagus daripada membiarkan satu video buruk lolos)."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Kurva ROC\n",
       "\n",
       "Kurva **Receiver Operating Characteristic (ROC)** adalah alat umum lain yang digunakan untuk *binary classifier*. Kurva ini memplot **True Positive Rate (Recall)** terhadap **False Positive Rate (FPR)**. FPR adalah rasio instance negatif yang salah diklasifikasikan sebagai positif.\n",
       "\n",
       "Ukuran kinerja yang baik adalah **Area Under the Curve (AUC)**. *Classifier* yang sempurna akan memiliki ROC AUC sama dengan 1, sedangkan *classifier* yang murni acak akan memiliki ROC AUC sama dengan 0.5."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from sklearn.metrics import roc_curve, roc_auc_score\n",
       "\n",
       "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
       "\n",
       "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
       "\n",
       "def plot_roc_curve(fpr, tpr, label=None):\n",
       "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
       "    plt.plot([0, 1], [0, 1], 'k--') # Garis putus-putus diagonal\n",
       "    plt.xlabel('False Positive Rate')\n",
       "    plt.ylabel('True Positive Rate (Recall)')\n",
       "    plt.grid(True)\n",
       "\n",
       "import matplotlib.pyplot as plt\n",
       "plot_roc_curve(fpr, tpr)\n",
       "plt.show()\n",
       "\n",
       "print(\"ROC AUC Score:\", roc_auc_score(y_train_5, y_scores))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Klasifikasi Multiclass, Multilabel, dan Multioutput"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Bab ini juga membahas cara memperluas tugas klasifikasi:\n",
       "\n",
       "* **Multiclass Classification:** Membedakan antara lebih dari dua kelas (misalnya, semua 10 digit di MNIST). Beberapa algoritma (seperti Random Forest) dapat menanganinya secara native, sementara yang lain (seperti SVM) adalah *binary classifier* murni. Untuk yang terakhir, Scikit-Learn secara otomatis menggunakan strategi **One-vs-the-Rest (OvR)** atau **One-vs-One (OvO)**.\n",
       "\n",
       "* **Multilabel Classification:** Sistem klasifikasi yang dapat mengeluarkan beberapa label biner untuk setiap instance. Contoh: *classifier* pengenal wajah yang dapat mendeteksi beberapa orang dalam satu gambar.\n",
       "\n",
       "* **Multioutput Classification:** Generalisasi dari *multilabel classification* di mana setiap label bisa *multiclass*. Contoh: sistem yang menghilangkan *noise* dari gambar, di mana setiap piksel adalah sebuah label dengan nilai dari 0 hingga 255."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }
   