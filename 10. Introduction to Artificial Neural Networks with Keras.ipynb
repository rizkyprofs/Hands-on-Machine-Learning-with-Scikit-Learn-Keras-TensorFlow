{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bab ini memulai bagian kedua dari buku ini, yang berfokus pada Jaringan Saraf Tiruan (Artificial Neural Networks - ANNs) dan Deep Learning. Kita akan beralih dari Scikit-Learn ke **TensorFlow** dan API tingkat tingginya, **Keras**.\n",
    "\n",
    "Kita akan membahas:\n",
    "* Konsep dasar ANN, mulai dari inspirasi biologisnya hingga arsitektur modern seperti **Multilayer Perceptron (MLP)**.\n",
    "* Bagaimana **backpropagation** bekerja untuk melatih ANN.\n",
    "* Implementasi ANN menggunakan Keras untuk tugas klasifikasi dan regresi.\n",
    "* Tiga API utama Keras: **Sequential API**, **Functional API**, dan **Subclassing API**.\n",
    "* Cara menyimpan dan memulihkan model, menggunakan *callbacks*, dan memvisualisasikan pelatihan dengan **TensorBoard**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Biological to Artificial Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN terinspirasi oleh arsitektur otak. Model paling awal adalah **Perceptron**, yang diperkenalkan oleh Frank Rosenblatt pada tahun 1957. Perceptron adalah arsitektur ANN paling sederhana, berdasarkan unit komputasi yang disebut *threshold logic unit (TLU)*.\n",
    "\n",
    "Sebuah TLU menghitung jumlah berbobot dari inputnya, lalu menerapkan *step function* untuk menghasilkan output. Sebuah Perceptron terdiri dari satu lapisan TLU. Namun, Perceptron memiliki kelemahan serius: mereka tidak mampu memecahkan beberapa masalah sepele (seperti masalah klasifikasi XOR). Keterbatasan ini dapat diatasi dengan menumpuk beberapa Perceptron, yang menghasilkan **Multilayer Perceptron (MLP)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP terdiri dari satu *input layer*, satu atau lebih *hidden layers*, dan satu *output layer*. Ketika sebuah ANN memiliki tumpukan *hidden layers* yang dalam, ia disebut **Deep Neural Network (DNN)**.\n",
    "\n",
    "MLP dilatih menggunakan algoritma **backpropagation**. Secara singkat, algoritma ini bekerja sebagai berikut:\n",
    "1. Setiap *mini-batch* data dilewatkan melalui jaringan (*forward pass*).\n",
    "2. Kesalahan (*error*) output jaringan diukur menggunakan *loss function*.\n",
    "3. Kontribusi setiap koneksi terhadap *error* dihitung dengan bergerak mundur melalui jaringan (*reverse pass*) menggunakan *chain rule* dari kalkulus.\n",
    "4. Bobot koneksi disesuaikan untuk mengurangi *error* menggunakan Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras adalah API tingkat tinggi untuk membangun, melatih, dan mengevaluasi jaringan saraf. Kita akan menggunakan `tf.keras`, implementasi Keras yang dibundel dengan TensorFlow.\n",
    "\n",
    "### Membangun Image Classifier menggunakan Sequential API\n",
    "**Sequential API** adalah cara paling sederhana untuk membuat model di Keras, cocok untuk jaringan yang hanya merupakan tumpukan lapisan tunggal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Memuat dataset Fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Membagi dan melakukan penskalaan data\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# Membuat model menggunakan Sequential API\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Melihat ringkasan model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengkompilasi model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Melatih model\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membangun Model Kompleks menggunakan Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk jaringan dengan topologi yang lebih kompleks, seperti yang memiliki banyak input atau output, kita dapat menggunakan **Functional API**. Ini memungkinkan kita untuk mendefinisikan grafik lapisan yang lebih rumit.\n",
    "\n",
    "Contohnya, kita bisa membuat arsitektur **Wide & Deep** yang menghubungkan beberapa input langsung ke *output layer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh Wide & Deep dengan multiple inputs\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan dan Memulihkan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras memudahkan penyimpanan model yang telah dilatih ke dalam satu file. File ini akan berisi arsitektur model, bobot, konfigurasi pelatihan (*loss*, *optimizer*), dan status *optimizer*, memungkinkan Anda untuk melanjutkan pelatihan tepat di tempat Anda berhenti.\n",
    "\n",
    "Untuk mencegah kehilangan progres pada pelatihan yang lama, kita dapat menggunakan *callbacks* seperti `ModelCheckpoint` untuk menyimpan *checkpoint* secara berkala, dan `EarlyStopping` untuk menghentikan pelatihan jika tidak ada kemajuan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"my_keras_model.h5\")\n",
    "# model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "\n",
    "# Contoh penggunaan callbacks\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=100,\n",
    "#                     validation_data=(X_valid, y_valid),\n",
    "#                     callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fleksibilitas jaringan saraf membawa banyak *hyperparameter* untuk disesuaikan. Kita bisa menggunakan `GridSearchCV` atau `RandomizedSearchCV` dari Scikit-Learn untuk menemukan kombinasi *hyperparameter* terbaik dengan membungkus model Keras kita.\n",
    "\n",
    "Beberapa *hyperparameter* kunci untuk disesuaikan:\n",
    "* **Jumlah *hidden layers***\n",
    "* **Jumlah neuron per *layer***\n",
    "* ***Learning rate***\n",
    "* ***Optimizer***\n",
    "* ***Batch size***\n",
    "* ***Activation function***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
