{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bab ini memperkenalkan **Support Vector Machines (SVMs)**, salah satu model Machine Learning yang sangat kuat dan serbaguna. SVM mampu melakukan klasifikasi linear maupun non-linear, regresi, dan bahkan deteksi outlier. SVM sangat cocok untuk dataset berukuran kecil hingga menengah yang kompleks.\n",
    "\n",
    "Ide fundamental di balik SVM adalah menemukan \"jalan\" terlebar (disebut *margin*) yang memisahkan kelas-kelas yang berbeda. Ini disebut **large margin classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM bekerja dengan membuat sebuah *decision boundary* yang tidak hanya memisahkan dua kelas, tetapi juga menjaga jarak sejauh mungkin dari *instance* pelatihan terdekat. *Instance* yang berada di tepi *margin* ini disebut **support vectors**, karena mereka yang \"mendukung\" atau menentukan *decision boundary*.\n",
    "\n",
    "### Soft Margin vs. Hard Margin Classification\n",
    "* **Hard Margin:** Mengharuskan semua *instance* berada di luar *margin* dan di sisi yang benar. Ini hanya berfungsi jika data dapat dipisahkan secara linear dan sangat sensitif terhadap *outlier*.\n",
    "* **Soft Margin:** Pendekatan yang lebih fleksibel di mana kita mencari keseimbangan antara menjaga *margin* selebar mungkin dan membatasi *margin violations* (yaitu, *instance* yang berakhir di dalam *margin* atau bahkan di sisi yang salah). Keseimbangan ini dikontrol oleh *hyperparameter* `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Memuat dataset iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.float64)  # Iris virginica\n",
    "\n",
    "# Membuat pipeline untuk penskalaan dan klasifikasi SVM\n",
    "svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", random_state=42))\n",
    "    ])\n",
    "\n",
    "svm_clf.fit(X, y)\n",
    "\n",
    "# Membuat prediksi\n",
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penting untuk melakukan penskalaan fitur (*feature scaling*) sebelum menggunakan SVM, karena SVM sensitif terhadap skala fitur yang berbeda-beda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Banyak dataset yang tidak dapat dipisahkan secara linear. Salah satu pendekatan untuk menangani data non-linear adalah dengan menambahkan lebih banyak fitur, seperti fitur polinomial. Namun, pendekatan yang lebih kuat dan ajaib pada SVM adalah dengan menggunakan **kernel trick**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menambahkan fitur polinomial dapat membuat dataset yang tidak linear menjadi dapat dipisahkan secara linear. Namun, ini bisa sangat lambat jika derajat polinomialnya tinggi. *Kernel trick* memungkinkan kita mendapatkan hasil yang sama seolah-olah kita menambahkan banyak fitur polinomial, tanpa benar-benar harus menambahkannya. Ini membuat SVM sangat efisien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Contoh menggunakan dataset moons\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
    "\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
    "])\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian RBF Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teknik lain untuk menangani masalah non-linear adalah dengan menambahkan fitur berdasarkan fungsi kesamaan (*similarity function*), yang mengukur seberapa mirip setiap *instance* dengan *landmark* tertentu. **Gaussian Radial Basis Function (RBF)** adalah fungsi kesamaan yang populer.\n",
    "\n",
    "Sama seperti *polynomial kernel*, *kernel trick* juga dapat diterapkan di sini, memungkinkan kita mendapatkan hasil yang sama seperti menambahkan banyak fitur kesamaan tanpa biaya komputasi yang besar.\n",
    "\n",
    "*Hyperparameter* `gamma` pada RBF kernel bertindak seperti *regularization*: jika model *overfitting*, turunkan `gamma`; jika *underfitting*, naikkan `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_kernel_svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "])\n",
    "rbf_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM juga dapat digunakan untuk regresi. Triknya adalah dengan membalik tujuannya: alih-alih mencoba memasang *margin* terlebar di antara dua kelas, SVM Regression mencoba memasukkan sebanyak mungkin *instance* ke dalam *margin* sambil membatasi *margin violations*.\n",
    "\n",
    "Lebar *margin* dikendalikan oleh *hyperparameter* `epsilon` ($\\epsilon$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "# Membuat data acak linear\n",
    "np.random.seed(42)\n",
    "m = 50\n",
    "X = 2 * np.random.rand(m, 1)\n",
    "y = (4 + 3 * X + np.random.randn(m, 1)).ravel()\n",
    "\n",
    "svm_reg = LinearSVR(epsilon=1.5, random_state=42)\n",
    "svm_reg.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
