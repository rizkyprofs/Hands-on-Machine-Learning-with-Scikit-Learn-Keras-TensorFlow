{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Custom Models and Training with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sejauh ini, kita telah menggunakan API tingkat tinggi TensorFlow, yaitu `tf.keras`. Meskipun sangat kuat, terkadang kita memerlukan kontrol lebih untuk menulis *loss function*, metrik, *layer*, atau bahkan *training loop* kustom.\n",
    "\n",
    "Bab ini akan menyelami API tingkat rendah TensorFlow. Kita akan belajar cara:\n",
    "* Menggunakan TensorFlow seperti NumPy untuk operasi tensor.\n",
    "* Membuat komponen Keras kustom: *loss*, *layer*, metrik, dan model.\n",
    "* Membuat *training loop* kustom dari awal.\n",
    "* Memanfaatkan fitur pembuatan grafik otomatis TensorFlow dengan `tf.function` untuk meningkatkan kinerja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Tour of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inti dari TensorFlow adalah pustaka komputasi numerik yang sangat mirip dengan NumPy, tetapi dengan dukungan GPU dan kemampuan komputasi terdistribusi. API-nya berpusat pada **tensor**, yang mengalir dari satu operasi ke operasi lainnya.\n",
    "\n",
    "Kita dapat membuat dan memanipulasi tensor dengan mudah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Membuat tensor\n",
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "\n",
    "# Operasi dasar\n",
    "print(\"Tensor + 10:\\n\", t + 10)\n",
    "print(\"\\nTensor kuadrat:\\n\", tf.square(t))\n",
    "print(\"\\nPerkalian matriks (t @ t_transpose):\\n\", t @ tf.transpose(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagian besar komponen Keras dapat dikustomisasi, biasanya dengan menulis sebuah fungsi sederhana atau dengan membuat *subclass* dari kelas yang relevan.\n",
    "\n",
    "### Custom Loss Functions\n",
    "Jika Anda membutuhkan *loss function* yang tidak tersedia di Keras, Anda dapat membuatnya sendiri. Contoh: Huber Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membuat Huber loss\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n",
    "\n",
    "# Penggunaannya saat kompilasi model\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layers\n",
    "Untuk lapisan tanpa bobot (*stateless*), kita bisa menggunakan `keras.layers.Lambda`. Untuk lapisan dengan bobot (*stateful*), kita perlu membuat *subclass* dari `keras.layers.Layer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh custom layer stateful sederhana (Dense layer versi simpel)\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam kasus yang jarang terjadi di mana metode `fit()` tidak cukup fleksibel (misalnya, jika ingin menggunakan dua *optimizer* yang berbeda untuk bagian yang berbeda dari jaringan), kita dapat menulis *training loop* kita sendiri. Ini memberi kita kontrol penuh atas proses pelatihan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh konseptual training loop kustom\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for step in range(1, n_steps + 1):\n",
    "        # Ambil batch data (contoh acak)\n",
    "        indices = np.random.randint(len(X_train), size=batch_size)\n",
    "        X_batch, y_batch = X_train[indices], y_train[indices]\n",
    "\n",
    "        # Hitung gradien di dalam GradientTape\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "        # Terapkan gradien\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions and Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk meningkatkan kinerja, TensorFlow dapat mengubah fungsi Python menjadi grafik komputasi statis. Ini dilakukan dengan menggunakan `tf.function` sebagai dekorator atau fungsi.\n",
    "\n",
    "Ketika sebuah fungsi didekorasi dengan `@tf.function`, TensorFlow akan melakukan *tracing* saat pertama kali dipanggil. Selama *tracing*, TensorFlow menganalisis kode Python dan membangun grafik komputasi yang setara dan dioptimalkan. Panggilan berikutnya akan menggunakan grafik ini, yang jauh lebih cepat daripada menjalankan kode Python baris per baris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3\n",
    "\n",
    "print(tf_cube(tf.constant(2.0)))\n",
    "print(tf_cube(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
