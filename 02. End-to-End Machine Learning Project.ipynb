{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892b3e20",
   "metadata": {},
   "source": [
    "# Chapter 2: End-to-End Machine Learning Project\n",
    "\n",
    "Bab ini memandu kita melalui proyek real-world dari awal hingga akhir, yaitu membangun model untuk memprediksi harga rumah di California menggunakan data sensus. Bab ini sangat praktis dan menunjukkan langkah-langkah utama yang harus diikuti dalam sebagian besar proyek Machine Learning.\n",
    "\n",
    "## Kerangka Proyek\n",
    "\n",
    "Berikut adalah langkah-langkah utama yang akan kita lalui\n",
    "\n",
    "1. Memahami Gambaran Besar: Mendefinisikan tujuan bisnis dan membingkai masalah.\n",
    "2. Mendapatkan Data: Mengunduh dan memuat data.\n",
    "3. Eksplorasi dan Visualisasi Data: Memahami data lebih dalam untuk mendapatkan wawasan.\n",
    "4. Mempersiapkan Data: Membersihkan dan mentransformasi data agar siap untuk algoritma ML.\n",
    "5. Memilih dan Melatih Model: Memilih beberapa model yang menjanjikan dan melatihnya.\n",
    "6. Fine-Tuning Model: Menyesuaikan hyperparameter untuk mendapatkan model terbaik.\n",
    "7. Menyajikan Solusi: Meringkas hasil dan temuan.\n",
    "8. Meluncurkan dan Memelihara Sistem: Men-deploy model ke produksi dan memonitornya.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f19bcb",
   "metadata": {},
   "source": [
    "### 1. Memahami Gambaran Besar\n",
    "\n",
    "* Tujuan Bisnis: Output dari model kita (prediksi harga median rumah di suatu distrik) akan menjadi masukan untuk sistem lain yang akan menentukan apakah layak berinvestasi di area tersebut atau tidak.\n",
    "* Pembingkaian Masalah:\n",
    "  - Supervised Learning: Ya, karena kita memiliki data berlabel (harga rumah).\n",
    "  - Tugas Regresi: Ya, karena kita akan memprediksi nilai numerik (harga).\n",
    "  - Batch Learning: Ya, karena kita tidak memerlukan sistem yang beradaptasi dengan data baru secara cepat.\n",
    "* Ukuran Kinerja: Metrik yang umum untuk regresi adalah Root Mean Square Error (RMSE). RMSE memberikan gambaran tentang seberapa besar kesalahan yang dibuat sistem dalam prediksinya, dengan memberikan bobot lebih pada kesalahan besar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56bdaa0",
   "metadata": {},
   "source": [
    "### 2. Mendapatkan Data\n",
    "Kita akan mengunduh dataset California Housing Prices. Penting untuk mengotomatiskan proses ini agar mudah mendapatkan data terbaru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40363bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d6b16",
   "metadata": {},
   "source": [
    "### 3. Eksplorasi dan Visualisasi Data\n",
    "\n",
    "Setelah data dimuat, langkah pertama adalah melihat strukturnya. Kita menggunakan head(), info(), dan describe() untuk mendapatkan gambaran awal. Penting juga untuk membuat test set sebelum melakukan eksplorasi mendalam untuk menghindari data snooping bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b661469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "# Membuat kategori pendapatan untuk stratified sampling\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "# Stratified sampling\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "# Hapus kolom income_cat\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc25010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi data geografis\\n\",\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4\n",
    "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7)\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f0181",
   "metadata": {},
   "source": [
    "Visualisasi menunjukkan bahwa harga rumah sangat terkait dengan lokasi (misalnya, dekat laut) dan kepadatan populasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mencari korelasi\\n\",\n",
    "corr_matrix = housing.corr()\n",
    "print(corr_matrix[\"median_house_value\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556d619",
   "metadata": {},
   "source": [
    "Fitur yang paling berkorelasi dengan harga rumah adalah pendapatan median (median_income)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfdbd0d",
   "metadata": {},
   "source": [
    "### 4. Mempersiapkan Data\n",
    "Langkah ini melibatkan pembersihan data (mengatasi nilai yang hilang), menangani atribut kategorikal, dan penskalaan fitur. Sebaiknya semua transformasi ini ditulis dalam fungsi atau pipeline agar dapat digunakan kembali.\n",
    "\n",
    "Kita akan membuat pipeline menggunakan ColumnTransformer dari Scikit-Learn untuk menerapkan transformasi yang berbeda pada kolom numerik dan kategorikal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7350db",
   "metadata": {},
   "source": [
    "### 5. Memilih dan Melatih Model\n",
    "Setelah data siap, saatnya melatih beberapa model. Kita akan mencoba Regresi Linear, Pohon Keputusan (Decision Tree), dan Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db49f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Melatih model Regresi Linear\n",
    "lin_reg = LinearRegression()\n",
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "\n",
    "# Melatih model Decision Tree\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-tree_scores)\n",
    "\n",
    "# Melatih model Random Forest\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "print(\"Linear Regression RMSE:\", lin_rmse_scores.mean())\n",
    "print(\"Decision Tree RMSE:\", tree_rmse_scores.mean())\n",
    "print(\"Random Forest RMSE:\", forest_rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2ddb3",
   "metadata": {},
   "source": [
    "Berdasarkan skor RMSE, Random Forest adalah model yang paling menjanjikan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f150e",
   "metadata": {},
   "source": [
    "### 6. Fine-Tuning Model\n",
    "Sekarang kita fokus pada model terbaik (Random Forest) dan mencoba menemukan kombinasi hyperparameter terbaik menggunakan GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "print(\"Best params:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffded333",
   "metadata": {},
   "source": [
    "Setelah menemukan hyperparameter terbaik, kita bisa menganalisis pentingnya setiap fitur dan mengevaluasi model final pada test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4000934",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "print(\"Final RMSE:\", final_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
